# 127. Word Ladder (Hard)

A **transformation sequence** from word `beginWord` to word `endWord` using a dictionary `wordList` is a sequence of words `beginWord -> s1 -> s2 -> ... -> sk` such that:

* Every adjacent pair of words differs by a single letter.
* Every `si` for `1 <= i <= k` is in `wordList`. Note that `beginWord` does not need to be in `wordList`.
* `sk == endWord`

Given two words, `beginWord` and `endWord`, and a dictionary `wordList`, return _the **number of words** in the **shortest transformation sequence** from_ `beginWord` _to_ `endWord`_, or_ `0` _if no such sequence exists._

**Example 1:**

<pre><code><strong>Input: beginWord = "hit", endWord = "cog", wordList = ["hot","dot","dog","lot","log","cog"]
</strong><strong>Output: 5
</strong><strong>Explanation: One shortest transformation sequence is "hit" -> "hot" -> "dot" -> "dog" -> cog", which is 5 words long.
</strong></code></pre>

**Example 2:**

<pre><code><strong>Input: beginWord = "hit", endWord = "cog", wordList = ["hot","dot","dog","lot","log"]
</strong><strong>Output: 0
</strong><strong>Explanation: The endWord "cog" is not in wordList, therefore there is no valid transformation sequence.
</strong></code></pre>

**Constraints:**

* `1 <= beginWord.length <= 10`
* `endWord.length == beginWord.length`
* `1 <= wordList.length <= 5000`
* `wordList[i].length == beginWord.length`
* `beginWord`, `endWord`, and `wordList[i]` consist of lowercase English letters.
* `beginWord != endWord`
* All the words in `wordList` are **unique**.



### Approach: BFS

1. **无向图**中两个顶点之间的**最短路径**的长度，可以通过BFS得到； 为什么 BFS 得到的路径最短？可以把起点和终点所在的路径拉直来看，两点之间线段最短；&#x20;
2. 已知**目标顶点**的情况下，可以分别从**起点和目标顶点（终点**）执行BFS，直到遍历的部分有交集，这是**双向广度优先遍历**的思想。

分析题意：

`「转换」`意即：两个单词对应位置只有一个字符不同，例如 "hit" 与 "hot"，这种转换是可以**逆向**的，因此，根据题目给出的单词列表，可以构建出一个**`无向（无权）图`**；

<figure><img src="../../../.gitbook/assets/image (41).png" alt="" width="375"><figcaption></figcaption></figure>

如果一开始就构建图，每一个单词都需要和除它以外的另外的单词进行比较，复杂度是 `O(N * wordLen)`，这里 N 是单词列表的长度； 为此，我们在遍历一开始，把所有的单词列表放进一个HashSet中，然后在遍历的时候构建图，每一次得到在单词列表里可以转换的单词，复杂度是 `O(26×wordLen)`，借助哈希表，找到邻居与 N 无关；

使用 BFS 进行遍历，需要的辅助数据结构是： Queue； visited 集合。说明：可以直接在 wordSet (由 wordList 放进集合中得到)里做删除。但更好的做法是新开一个visited HashSet，遍历过的字符串放进哈希表里。这种做法具有普遍意义。绝大多数在线测评系统和应用场景都不会在意空间开销。

```java
class Solution {
    public int ladderLength(String beginWord, String endWord, List<String> wordList) {
        // 第 1 步：先将 wordList 放到哈希表里，便于判断某个单词是否在 wordList 里
        Set<String> wordSet = new HashSet<>(wordList);
        if (!wordSet.contains(endWord)) {
            return 0;
        }
        wordSet.remove(beginWord);

        // 第 2 步：图的广度优先遍历，必须使用队列和表示是否访问过的 visited 哈希表
        Queue<String> queue = new LinkedList<>();
        queue.offer(beginWord);
        Set<String> visited = new HashSet<>();
        visited.add(beginWord);

        // 第 3 步：开始广度优先遍历，包含起点，因此初始化的时候步数为 1
        int step = 1;
        while (!queue.isEmpty()) {
            int size = queue.size();
            for (int i = 0; i < size; i++) {
                String currWord = queue.poll();
                if (changeEveryLetter(currWord, endWord, queue, visited, wordSet)) {
                    return step + 1;
                }
            }
            step++;
        }

        return 0;
    }

    private boolean changeEveryLetter(String currWord, String endWord, Queue<String> queue, Set<String> visited, Set<String> wordSet) {
        char[] charArr = currWord.toCharArray();
        for (int i = 0; i < endWord.length(); i++) {
            char original = charArr[i]; // 先保存，然后恢复
            for (char c = 'a'; c <= 'z'; c++) {
                if (c == original) continue;

                charArr[i] = c;
                String nextWord = String.valueOf(charArr);
                if (wordSet.contains(nextWord)) {
                    if (nextWord.equals(endWord)) {
                        return true;
                    }

                    if (!visited.contains(nextWord)) {
                        queue.offer(nextWord);
                        visited.add(nextWord);
                    }
                }
            }
            charArr[i] = original;
        }

        return false;
    }
}
```

### Complexity Analysis

* Time complexity: O(M × N), where M is the length of words and N is the total number of words in the input word list. Finding out all the transformations takes M iterations for each of the N words. Also, breadth first search in the worst case might go to each of the N words.
* Space complexity: O(M × N), to store all M transformations for each of the N words, in the all\_combo\_dict dictionary. Visited dictionary is of N size. Queue for BFS in worst case would need space for all N words.

### Optimization: Double BFS

已知目标顶点的情况下，可以分别从起点和目标顶点（终点）执行广度优先遍历，直到遍历的部分有交集。这种方式搜索的单词数量会更小一些； 更合理的做法是，**每次从单词数量小的集合开始扩散**； 这里 beginVisited 和 endVisited 交替使用，等价于单向 BFS 里使用队列，每次扩散都要加到总的 visited 里。

<figure><img src="../../../.gitbook/assets/image (42).png" alt="" width="375"><figcaption></figcaption></figure>
